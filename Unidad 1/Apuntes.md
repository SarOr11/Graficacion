# Unidad I: Introducción a la graficación por computadora

## Índice
[1.1 Historia y y Evolución de la Graficación por Computadora](##1.1-historia-y-evolución-de-la-graficación-por-computadora)

[1.2 Áreas de Aplicación](##1.2-áreas-de-aplicación)

[1.3 Aspectos Matemáticos de la Graficación](##1.3-aspectos-matemáticos-de-la-graficación)

[1.4. Modelos del Color RGB, CMY y HSV](##1.4-modelos-del-color-rgb-cmy-y-hsv)

[1.5. Representación y Trazo de Líneas y Polígonos](##1.5-representación-y-trazo-de-líneas-y-polígonos)

[1.6. Procesamiento de Mapas de Bits](##1.6-procesamiento-de-mapas-de-bits)

[Referencias](##referencias)


## 1.1 Historia y Evolución de la Graficación por Computadora


<img width="751" height="352" alt="Image" src="https://github.com/user-attachments/assets/1c43ab2d-ba53-4cce-8321-7a1076a57b55" />

La graficación por computadora es una disciplina que ha experimentado una transformación profunda desde sus orígenes en la década de 1950 hasta convertirse en uno de los campos tecnológicos más influyentes de la era contemporánea. Su desarrollo no puede comprenderse de forma aislada; está íntimamente vinculado con la evolución del hardware, los avances en matemáticas aplicadas, la programación y las demandas de industrias tan diversas como la medicina, el entretenimiento, la ingeniería y las comunicaciones.


### **Orígenes: Décadas de 1950 y 1960**

Los primeros indicios de la graficación por computadora aparecieron en el contexto de la Segunda Guerra Mundial y la posguerra, cuando los sistemas de radar comenzaron a visualizar datos en pantallas de tubos de rayos catódicos (CRT). En 1950, el MIT desarrolló el sistema Whirlwind, una computadora capaz de mostrar gráficos en tiempo real. Sin embargo, el hito más significativo de esta era fue la tesis doctoral de Ivan Sutherland en 1963, denominada Sketchpad: A Man-Machine Graphical Communication System, donde se introdujo el primer sistema de dibujo interactivo por computadora. Sketchpad permitía al usuario crear y manipular figuras geométricas mediante un lápiz óptico, sentando las bases de la interacción hombre-máquina y la geometría computacional.

<img width="821" height="320" alt="Image" src="https://github.com/user-attachments/assets/0e828f28-6e47-4336-9830-d79baaf57c60" />


### **Consolidación: Décadas de 1970 y 1980**

Los años setenta representaron una etapa decisiva para la graficación por computadora. La investigación académica floreció en universidades como Utah, donde Henri Gouraud desarrolló el sombreado suave que lleva su nombre, y Bui Tuong Phong introdujo su modelo de iluminación, ambos fundamentales para la síntesis de imágenes realistas. Simultáneamente, Ed Catmull —quien más tarde cofundaría Pixar— aportó contribuciones esenciales sobre superficies paramétricas y mapeo de texturas.
En 1977, George Lucas fundó el grupo de gráficos por computadora de Lucasfilm, que posteriormente se convertiría en Pixar Animation Studios en 1986. 
La década de 1980 fue testigo del auge de las estaciones de trabajo gráficas, como las de Silicon Graphics Inc. (SGI), que permitieron visualizaciones tridimensionales complejas. En 1982, la película Tron de Disney incorporó secuencias generadas por computadora, marcando un punto de inflexión en el uso del CGI (Computer Generated Imagery) en la industria del entretenimiento.

<img width="860" height="432" alt="Image" src="https://github.com/user-attachments/assets/3e1d2491-2ea7-4d0a-aeb6-e8c19527623c" />


### **Madurez Tecnológica: Décadas de 1990 y 2000**

La aparición de la tarjeta gráfica aceleradora 3D en los años noventa democratizó la graficación por computadora. Empresas como NVIDIA y ATI comenzaron a producir unidades de procesamiento gráfico (GPU) que trasladaron el cálculo de imágenes del CPU a hardware especializado, incrementando exponencialmente la capacidad de renderizado en tiempo real. En 1995, Toy Story de Pixar se convirtió en el primer largometraje animado completamente generado por computadora, un logro que revolucionó la industria cinematográfica.

<img width="817" height="282" alt="Image" src="https://github.com/user-attachments/assets/44f9c03c-6a5f-4f2d-b646-3b4dc820c76f" />


### **Era Contemporánea: Desde 2010 hasta el Presente**

El siglo XXI ha traído consigo avances sin precedentes en la graficación por computadora. El desarrollo de motores de renderizado como Unreal Engine y Unity ha permitido crear experiencias visuales fotorrealistas accesibles para desarrolladores independientes. La computación en la nube ha posibilitado el renderizado distribuido, eliminando la necesidad de infraestructuras locales costosas.
El surgimiento de la inteligencia artificial y el aprendizaje profundo ha abierto nuevas fronteras: redes generativas adversariales (GAN) son capaces de generar imágenes fotorrealistas de personas, escenarios y objetos que nunca han existido. Las tecnologías de realidad virtual (VR) y realidad aumentada (AR) han expandido los dominios de aplicación de la graficación, integrándola en medicina, educación, arquitectura y entretenimiento de maneras que hace apenas dos décadas parecían ciencia ficción.

<img width="732" height="253" alt="Image" src="https://github.com/user-attachments/assets/d7c97a91-cd3d-41ac-b433-554def60fd41" />



## 1.2 Áreas de Aplicación


<img width="907" height="467" alt="Image" src="https://github.com/user-attachments/assets/59ac026c-fb67-4b79-8328-6f0fb30c1085" />

La graficación por computadora es hoy una disciplina transversal cuya influencia permea prácticamente todos los sectores del conocimiento humano y la actividad productiva. Sus aplicaciones van desde la visualización científica hasta el arte digital, pasando por la medicina, la ingeniería, la educación y el entretenimiento. A continuación, se describen las principales áreas de aplicación.

- **Entretenimiento Digital y Medios de Comunicación**
La industria del entretenimiento es uno de los sectores que más ha impulsado el desarrollo de la graficación por computadora. Los efectos visuales (VFX) en el cine permiten recrear escenarios imposibles, criaturas fantásticas y destrucciones masivas con un nivel de realismo asombroso. Series de televisión como The Mandalorian han incorporado entornos virtuales generados en tiempo real mediante el motor Unreal Engine, sustituyendo los fondos físicos por pantallas LED de alta resolución sincronizadas con gráficos computarizados.
La industria de los videojuegos, valorada en cientos de miles de millones de dólares a nivel global, depende enteramente de la graficación en tiempo real. Los avances en iluminación global, simulación de físicas y shaders fotorrealistas han convertido a los videojuegos modernos en experiencias visuales equiparables al cine. 

- **Diseño Asistido por Computadora (CAD/CAM)**
En el campo de la ingeniería y la manufactura, el diseño asistido por computadora (CAD) y la manufactura asistida por computadora (CAM) son herramientas indispensables. Mediante software como AutoCAD, SolidWorks o CATIA, los ingenieros pueden diseñar piezas mecánicas complejas, estructuras arquitectónicas y componentes electrónicos con precisión milimétrica. La graficación permite visualizar prototipos virtuales en tres dimensiones antes de su fabricación, reduciendo costos y tiempos de desarrollo.


- **Medicina e Imágenes Diagnósticas**
La visualización médica es una de las áreas donde la graficación por computadora tiene mayor impacto en la calidad de vida humana. Las técnicas de reconstrucción volumétrica permiten generar modelos tridimensionales a partir de tomografías computarizadas (TC) y resonancias magnéticas (RM), facilitando el diagnóstico de enfermedades y la planificación quirúrgica. Los cirujanos pueden explorar virtualmente el interior del cuerpo humano antes de una intervención, identificando estructuras críticas y planificando rutas de acceso seguras.

- **Arquitectura y Urbanismo**
La visualización arquitectónica permite a diseñadores y clientes explorar edificios y espacios antes de su construcción. Mediante renders fotorrealistas y recorridos virtuales interactivos, es posible evaluar aspectos estéticos, funcionales y ambientales de un proyecto. Herramientas como Revit, Rhino y 3ds Max integran la graficación con el modelado de información de construcción (BIM), permitiendo gestionar proyectos de gran escala con múltiples variables simultáneas.

- **Educación y Simulación**
Los entornos virtuales de aprendizaje y los simuladores educativos aprovechan la graficación por computadora para crear experiencias inmersivas. Los pilotos de aviación, los conductores de vehículos pesados y el personal médico reciben entrenamiento en simuladores que replican fielmente condiciones reales, reduciendo el riesgo asociado al aprendizaje en situaciones peligrosas. La realidad virtual está transformando la educación al permitir a los estudiantes explorar el sistema solar, recorrer monumentos históricos o diseccionar organismos de forma virtual.

- **Visualización Científica y Análisis de Datos**
En las ciencias, la graficación es fundamental para interpretar grandes volúmenes de datos. La visualización de simulaciones climáticas, modelos de dinámica de fluidos computacional (CFD), redes moleculares y estructuras cristalinas permite a los investigadores identificar patrones y relaciones que serían imposibles de detectar en tablas numéricas. Herramientas como ParaView, VTK y MATLAB integran capacidades gráficas avanzadas para el análisis científico.



## 1.3. Aspectos Matemáticos de la Graficación


<img width="902" height="537" alt="Image" src="https://github.com/user-attachments/assets/7a3fc892-7197-43ef-941a-2ca045aa0532" />

La graficación por computadora descansa sobre un sólido fundamento matemático. Sin la correcta comprensión de sus bases teóricas, es imposible implementar algoritmos eficientes o comprender el comportamiento de los sistemas gráficos. Los aspectos matemáticos más relevantes incluyen el álgebra lineal, la geometría analítica, la trigonometría, el cálculo diferencial e integral y la teoría de curvas y superficies.

### **Sistemas de Coordenadas**

El sistema de coordenadas cartesianas es el fundamento sobre el cual se construyen los espacios gráficos. En graficación bidimensional se trabaja con un plano definido por los ejes X e Y, mientras que en la graficación tridimensional se agrega el eje Z para representar la profundidad. La conversión entre diferentes sistemas de coordenadas —cartesianas, polares, cilíndricas y esféricas— es una operación frecuente en la implementación de algoritmos gráficos.
Las coordenadas homogéneas constituyen una extensión del sistema cartesiano que simplifica enormemente las transformaciones geométricas. Al representar un punto en el espacio 2D como (x, y, w) o en 3D como (x, y, z, w), es posible unificar las transformaciones de traslación, rotación, escala y proyección en operaciones matriciales, lo que facilita su implementación en hardware gráfico.

### **Álgebra Lineal y Transformaciones Geométricas**

El álgebra lineal es quizás la herramienta matemática más fundamental en la graficación por computadora. Los vectores y matrices permiten representar y manipular objetos geométricos de forma eficiente. Las transformaciones afines básicas se expresan mediante matrices cuadradas:
- **Traslación:** Desplaza un objeto en el espacio sumando un vector de desplazamiento. En coordenadas homogéneas, se representa con una matriz de identidad aumentada con el vector de traslación en la última columna.
- **Escala:** Modifica las dimensiones de un objeto multiplicando sus coordenadas por factores de escala en cada eje. La matriz de escala es una matriz diagonal con los factores correspondientes.
- **Rotación**: Gira un objeto alrededor de un eje mediante matrices que contienen funciones trigonométricas (seno y coseno del ángulo de rotación). En 3D existen matrices de rotación para cada uno de los tres ejes principales.
- **Cizallamiento (Shear):** Deforma un objeto desplazando sus puntos en una dirección proporcional a su posición en otra dirección.
La composición de transformaciones se logra multiplicando las matrices correspondientes, lo que permite aplicar secuencias complejas de operaciones geométricas de forma eficiente. La pipeline de transformaciones típica en graficación 3D incluye la transformación de modelo (model transform), la transformación de vista (view transform) y la transformación de proyección (projection transform).

### **Curvas y Superficies Paramétricas**

Para representar formas curvas complejas, la graficación por computadora utiliza representaciones paramétricas. Las curvas de Bézier, desarrolladas por Pierre Bézier y Paul de Casteljau en la industria automotriz, definen trayectorias curvas mediante puntos de control. Una curva de Bézier cúbica está definida por cuatro puntos de control y se calcula mediante los polinomios de Bernstein:
B(t) = (1-t)³P₀ + 3t(1-t)²P₁ + 3t²(1-t)P₂ + t³P₃, donde t ∈ [0,1]
Las curvas B-spline (Base Spline) son una generalización de las curvas de Bézier que ofrecen control local: modificar un punto de control afecta solo una región limitada de la curva. Las superficies NURBS (Non-Uniform Rational B-Splines) extienden este concepto a superficies tridimensionales y son el estándar en la industria de CAD y modelado 3D por su capacidad de representar con exactitud matemática tanto formas geométricas regulares como formas orgánicas complejas.

### **Iluminación y Modelos de Color**

Los modelos matemáticos de iluminación describen cómo la luz interactúa con las superficies. El modelo de Phong descompone la iluminación en tres componentes: luz ambiental (iluminación uniforme de fondo), luz difusa (reflexión en todas las direcciones, dependiente del ángulo de incidencia) y luz especular (reflexión brillante dependiente del ángulo de observación).

<img width="782" height="330" alt="Image" src="https://github.com/user-attachments/assets/95bc9686-b0fb-499e-b207-5a287503d58a" />

### **Algoritmos de Rasterización**

La rasterización es el proceso de convertir geometría vectorial en píxeles para su visualización en pantalla. El algoritmo de Bresenham para la trazado de líneas utiliza aritmética entera para determinar eficientemente qué píxeles activar al dibujar una línea entre dos puntos. De manera similar, los algoritmos de relleno de polígonos utilizan técnicas como el scanline fill, que recorre horizontalmente la imagen determinando los segmentos interiores del polígono en cada línea de barrido.
El problema de visibilidad —determinar qué superficies son visibles desde el punto de observación— se resuelve mediante algoritmos como el Z-buffer (buffer de profundidad), que mantiene para cada píxel el valor de profundidad del objeto más cercano, asegurando la correcta oclusión entre objetos tridimensionales.

<img width="655" height="293" alt="Image" src="https://github.com/user-attachments/assets/d6f229ee-f808-4789-9fd9-49509730ee77" />


## 1.4. Modelos del Color RGB, CMY y HSV 


El color es una percepción subjetiva producida por la estimulación de los fotorreceptores del ojo humano ante la luz. Para trabajar con color en sistemas computacionales, es indispensable disponer de representaciones matemáticas precisas que permitan codificarlo, transmitirlo y reproducirlo de manera consistente. Los modelos del color son marcos conceptuales que describen las relaciones entre los colores y proveen las herramientas para su manipulación digital. Cada modelo responde a necesidades y contextos específicos: algunos están orientados al hardware de visualización, otros a la impresión, y otros a la intuición del diseñador humano.

### **Tabla comparativa de modelos de color**

<img width="857" height="272" alt="Image" src="https://github.com/user-attachments/assets/bc980179-1992-45ff-946e-72d14a356790" />

### **1.4.1 Modelo RGB (Red, Green, Blue)**

El modelo RGB es un modelo aditivo de color basado en los tres colores primarios de la luz: rojo (R), verde (G) y azul (B). Se denomina aditivo porque los colores se obtienen sumando componentes de luz; cuando las tres componentes están en su valor máximo se produce el blanco, y cuando todas son cero se obtiene el negro. Este principio reproduce el funcionamiento de los conos del ojo humano, que son sensibles precisamente a estas tres longitudes de onda.

- Cada canal de color se representa típicamente con un valor entero de 8 bits, en el rango [0, 255], lo que produce 256³ = 16,777,216 colores posibles. En representaciones de punto flotante normalizadas, el rango es [0.0, 1.0]. El color se expresa como una tripla ordenada (R, G, B), de modo que el rojo puro es (255, 0, 0), el verde puro es (0, 255, 0) y el azul puro es (0, 0, 255).
- El espacio de color RGB puede visualizarse como un cubo unitario en el que cada eje representa una de las componentes. Los vértices del cubo corresponden a los colores primarios y secundarios: magenta (255, 0, 255), cian (0, 255, 255), amarillo (255, 255, 0) y negro (0, 0, 0). 
- Este modelo es el estándar para monitores, televisiones, cámaras digitales y cualquier dispositivo de visualización basado en emisión de luz.

<img width="892" height="633" alt="Image" src="https://github.com/user-attachments/assets/d0a0a9a1-63d0-4682-9a43-ce3b79310312" />

### **1.4.2 Modelo CMY y CMYK (Cian, Magenta, Amarillo, Negro)**

El modelo CMY es el complemento sustractivo del RGB. Mientras que el RGB trabaja con luz emitida, el CMY trabaja con tintas o pigmentos que absorben ciertas longitudes de onda y reflejan otras. Al mezclar tintas, los colores se sustraen del espectro de luz blanca reflejada por el papel. Los colores primarios sustractivos son el cian (absorbe rojo), el magenta (absorbe verde) y el amarillo (absorbe azul).

- La conversión entre RGB y CMY es directa mediante la relación: C = 1 - R, M = 1 - G, Y = 1 - B (en valores normalizados). En teoría, la mezcla de cian, magenta y amarillo en proporciones iguales produce negro; sin embargo, en la práctica impresa esto genera un gris oscuro impuro y consume grandes cantidades de tinta. Por esta razón, el modelo se extiende a CMYK, donde K representa el negro (Black, escrito como K para evitar confusión con el azul), que se usa directamente para imprimir sombras y texto. 
- Este modelo es el estándar en la industria de la impresión offset, gráfica editorial y diseño para medios impresos.

<img width="842" height="486" alt="Image" src="https://github.com/user-attachments/assets/0f4a8376-afe4-47dc-a627-92ccd4170f5c" />

### **1.4.3 Modelo HSV (Hue, Saturation, Value)**

El modelo HSV surge de la necesidad de contar con un espacio de color más intuitivo para el diseñador humano. En lugar de pensar en proporciones de rojo, verde y azul, el usuario trabaja con conceptos más naturales: el matiz (Hue), que indica el color puro; la saturación (Saturation), que describe la pureza o intensidad del color; y el valor (Value), que corresponde al brillo o luminosidad.
- **Matiz (H)**: Se representa como un ángulo en el círculo cromático, con valores en el rango [0°, 360°]. 0° corresponde al rojo, 120° al verde, 240° al azul. Los valores intermedios producen los colores secundarios y terciarios del espectro visible.
- **Saturación (S)**: Varía de 0 a 1. Una saturación de 0 produce escala de grises; una saturación de 1 produce el color más puro posible para ese matiz.
- **Valor (V)**: También entre 0 y 1. Un valor de 0 siempre produce negro independientemente del matiz y la saturación; un valor de 1 produce el color más brillante posible.
- Geométricamente, el espacio HSV se representa como un cono o un cilindro hexagonal. El modelo HSV es ampliamente utilizado en selectores de color de software de diseño gráfico como Adobe Photoshop, GIMP y Blender, ya que permite al artista ajustar el brillo y la saturación de forma independiente al matiz, facilitando la creación de paletas armoniosas.

<img width="506" height="330" alt="Image" src="https://github.com/user-attachments/assets/e3350de4-13de-49cf-aeb5-8d15319f31de" />


### **Tutorial: Materiales en un Cubo en Blender 5.0**

- **Paso 1**: A modo de traer a la vida una malla, en este caso un cubo necesitamos añadir un objeto a la escena y, posteriormente, seleccionar la pestaña "Material":

<img width="1918" height="932" alt="Image" src="https://github.com/user-attachments/assets/f3904470-be77-4d95-a0de-a9fa9af84f5b" />

- **Paso 2**: En la opción "Superficie", existen diversas formas para colorear una malla. Una vez seleccionada, procedemos a elegir el color base y otros colores secundarios siempre que sea posible. Es importante tener la vista "Previsualización de materiales" activada para poder visualizar estos cambios.

<img width="1900" height="951" alt="Image" src="https://github.com/user-attachments/assets/9222aa4a-ef15-48f1-996d-d92f0f62ebf7" />

- **Paso 3**: Estos materiales pueden aplicarse a otros objetos. Experimentando con los diferentes parámetros podemos obtener efectos interesantes.

<img width="1917" height="986" alt="Image" src="https://github.com/user-attachments/assets/3c5af0cc-047f-40a3-b9bd-5da8879e205a" />



## 1.5. Representación y Trazo de Líneas y Polígonos


<img width="846" height="430" alt="Image" src="https://github.com/user-attachments/assets/90a4a272-886a-4d9a-bd3a-1a61876bbad4" />

La representación y el trazo de primitivas geométricas —principalmente líneas y polígonos— constituyen la base de la graficación por computadora en modo raster (basada en píxeles). Toda imagen computacional compleja puede descomponerse en estas primitivas fundamentales, que deben ser convertidas desde su representación matemática continua a una representación discreta en la cuadrícula de píxeles de una pantalla. Este proceso se denomina rasterización o scan conversion.

### **Representación Matemática de Líneas**

Una línea recta en el plano puede definirse de múltiples formas matemáticas. La representación implícita mediante la ecuación ax + by + c = 0 define todos los puntos que pertenecen a la línea, pero no es directamente útil para el trazo. En la cuadrícula de píxeles, trazar una línea implica seleccionar cuáles celdas (píxeles) mejor aproximan la trayectoria matemática continua. Este problema, aparentemente simple, requiere algoritmos eficientes dado que en aplicaciones gráficas se trazan millones de líneas por segundo.

- **Algoritmo DDA (Digital Differential Analyzer)**
El algoritmo DDA es el más sencillo para trazar líneas. Calcula la pendiente de la línea m = (y₁ - y₀)/(x₁ - x₀) y recorre el eje dominante en incrementos unitarios, calculando la coordenada en el otro eje acumulando la pendiente. 
Si bien el DDA es conceptualmente simple, presenta la desventaja de utilizar aritmética de punto flotante, con el costo computacional que esto implica. Para evitarlo, el algoritmo de Bresenham proporciona una solución más eficiente.


- **Algoritmo de Bresenham para Líneas**
El algoritmo de Bresenham (1965) es uno de los algoritmos más elegantes en la historia de la graficación por computadora. Su mérito es que utiliza únicamente aritmética entera para determinar qué píxel activar en cada paso, haciéndolo extraordinariamente eficiente.
La idea central es mantener una variable de decisión d que determina si el siguiente píxel debe estar a la misma altura o un nivel arriba. Partiendo del punto inicial (x₀, y₀), en cada iteración x aumenta en 1, y el criterio de decisión se actualiza como:
Si d < 0: activar (x+1, y),     d_nuevo = d + 2Δy
Si d ≥ 0: activar (x+1, y+1),   d_nuevo = d + 2Δy - 2Δx
Valor inicial: d = 2Δy - Δx
El algoritmo de Bresenham se extiende naturalmente para el trazo de circunferencias y elipses, aprovechando la simetría de estas figuras para calcular los 360° a partir de un solo octante, lo que reduce el cálculo a solo 45 grados de arco con espejado.

- **Antialiasing**
Un problema inherente a la rasterización es el aliasing: los bordes de líneas y polígonos presentan un efecto de 'escalera' (jaggies) debido a la discretización en píxeles cuadrados. El antialiasing es el conjunto de técnicas que suavizan este efecto.
El método de antialiasing por submuestreo (SSAA, Supersampling Anti-Aliasing) renderiza la imagen a una resolución múltiplo de la final y luego la reduce, promediando los valores de color de los subpíxeles. El MSAA (Multisample AA) aplica múltiples muestras solo en los bordes de los polígonos, reduciendo el costo computacional. El método de Wu utiliza la intensidad ponderada de dos píxeles adyacentes proporcional a la distancia del píxel a la línea ideal, produciendo bordes suavizados con costo mínimo.

- **Relleno de Polígonos**
Para rellenar polígonos, el algoritmo más común es el Scanline Fill. Este recorre horizontalmente la imagen línea a línea (scanline), determina en qué puntos cada scanline intersecta los bordes del polígono y rellena el interior entre cada par de intersecciones. La eficiencia del algoritmo depende de estructuras de datos auxiliares como la Edge Table (ET) y la Active Edge Table (AET).
El algoritmo de relleno por inundación (Flood Fill) parte de un píxel semilla interior al polígono y expande el relleno hacia los píxeles adyacentes del mismo color hasta alcanzar los bordes. Existen variantes de 4-conectividad (conecta píxeles adyacentes en las cuatro direcciones cardinales) y 8-conectividad (incluye además las diagonales).

<img width="785" height="287" alt="Image" src="https://github.com/user-attachments/assets/16fc99bf-e1f7-4ad6-b6a8-3be6711b872b" />


### **Práctica**


**1. Polígono en Blender**

Este proyecto demuestra el uso de la API de Python en Blender (bpy) para la creación automatizada de geometrías 2D. Se utiliza la conversión de coordenadas polares a cartesianas para posicionar vértices y generar polígonos regulares de n lados.

<img width="1918" height="1022" alt="Image" src="https://github.com/user-attachments/assets/c7ed8b7d-c19d-4fa2-bee5-90093df2facf" />

<img width="1920" height="1015" alt="Image" src="https://github.com/user-attachments/assets/baed7fc8-a9ea-4689-89fe-dfcc11c174e2" />


**2. Flor de Vida**

En esta práctica se explora la creación de patrones complejos mediante la repetición de primitivas geométricas. Utilizando el módulo math de Python, calculamos posiciones siguiendo una trayectoria circular para crear una estructura basada en el concepto de la "Flor de la Vida" o patrones radiales.

<img width="1917" height="1016" alt="Image" src="https://github.com/user-attachments/assets/096b4526-f5ea-416d-92a2-aaea7f8cf3da" />

<img width="1918" height="1016" alt="Image" src="https://github.com/user-attachments/assets/1bf3d3e1-2e4f-40e1-bf09-f0ecb8399280" />


---
### **1.5.1 Formatos de Imagen**
---

Los formatos de imagen definen la estructura y codificación con la que se almacena la información visual en un archivo digital. La elección del formato adecuado impacta directamente en la calidad visual, el tamaño del archivo, la capacidad de edición posterior y la compatibilidad con diferentes aplicaciones y plataformas. Desde la perspectiva de la graficación por computadora, es fundamental comprender las diferencias técnicas entre los formatos para tomar decisiones informadas en el desarrollo de aplicaciones gráficas.


### **Clasificación General de los Formatos**
- **Formatos de mapa de bits (raster):** Almacenan la imagen como una cuadrícula de píxeles. Su calidad depende de la resolución; al ampliarlos se produce pérdida de calidad (pixelación). Son adecuados para fotografías y texturas.
- **Formatos vectoriales**: Almacenan la imagen como instrucciones matemáticas (curvas, líneas, formas). Son escalables sin pérdida de calidad. Son adecuados para logotipos, iconos y gráficos de interfaz.

### **Tabla Comparativa**

<img width="820" height="507" alt="Image" src="https://github.com/user-attachments/assets/cb7574e7-ea23-495f-b96c-18292f91241f" />

- **BMP (Bitmap)**
El formato BMP fue desarrollado por Microsoft para el sistema operativo Windows. Almacena los píxeles sin compresión (o con compresión RLE opcional), lo que resulta en archivos de gran tamaño. Cada píxel se almacena directamente con sus valores de color en 24 o 32 bits. La simplicidad de su estructura lo hace fácil de leer y escribir, razón por la que sigue utilizándose como formato interno en aplicaciones de procesamiento de imágenes. Sin embargo, no es adecuado para distribución web debido a su gran tamaño.

- **JPEG (Joint Photographic Experts Group)**
El formato JPEG aplica compresión con pérdida basada en la Transformada Discreta del Coseno (DCT). La imagen se divide en bloques de 8×8 píxeles, cada bloque se transforma al dominio de frecuencias mediante la DCT, y las componentes de alta frecuencia (detalles finos) se reducen o eliminan según el nivel de compresión especificado por el parámetro de calidad (0-100).
La compresión JPEG aprovecha dos características del sistema visual humano: la mayor sensibilidad al cambio de luminosidad que al cambio de color (submuestreo de crominancia), y la menor sensibilidad a las altas frecuencias espaciales. A niveles de calidad mayores a 85%, la pérdida suele ser imperceptible para el ojo humano. A niveles bajos, aparecen los característicos artefactos de bloque. JPEG no soporta transparencia y no es adecuado para imágenes con bordes nítidos, texto o gráficos de líneas.

- **PNG (Portable Network Graphics)**
PNG fue diseñado como sucesor sin patentes del formato GIF. Utiliza compresión sin pérdida mediante el algoritmo Deflate (basado en LZ77 y Huffman), lo que garantiza que la imagen descomprimida es idéntica a la original. Su característica más destacada es el soporte para canal alpha (transparencia), con 256 niveles de opacidad por píxel, lo que lo hace ideal para la composición de capas en diseño gráfico y desarrollo web.
PNG soporta diferentes modos de color: escala de grises (1-16 bits), RGB (24 o 48 bits) y RGBA (32 o 64 bits). Dado que no pierde calidad, resulta en archivos más grandes que JPEG para fotografías, pero es superior para capturas de pantalla, interfaces de usuario, iconos y cualquier imagen que requiera bordes nítidos o transparencia.

- **GIF (Graphics Interchange Format)**
El formato GIF utiliza compresión LZW sin pérdida, pero está limitado a una paleta de 256 colores, lo que lo hace inadecuado para fotografías. Su mayor característica es el soporte para animaciones mediante múltiples fotogramas almacenados en el mismo archivo, con control de retardo entre cuadros. Aunque tecnológicamente superado por formatos como WebP y APNG para animaciones, el GIF sigue siendo ampliamente utilizado en redes sociales y plataformas web por razones culturales y de compatibilidad universal.

- **TIFF (Tagged Image File Format)**
TIFF es un formato extremadamente flexible que soporta múltiples métodos de compresión (sin compresión, LZW, ZIP, JPEG, entre otros), múltiples espacios de color (RGB, CMYK, LAB, escala de grises), profundidades de bit elevadas (hasta 32 bits por canal en punto flotante), múltiples capas y páginas dentro de un mismo archivo, y metadatos extensos. Esta flexibilidad lo convierte en el estándar para la industria editorial, la fotografía profesional (junto con RAW) y las aplicaciones de medicina e imágenes satelitales donde se requiere máxima fidelidad.

- **SVG (Scalable Vector Graphics)**
SVG es un formato vectorial basado en XML, desarrollado por el W3C. Al ser un lenguaje de marcado textual, las imágenes SVG son editables con cualquier editor de texto, accesibles para motores de búsqueda e indexables. Soportan animación mediante CSS y JavaScript, lo que los hace ideales para infografías interactivas, iconos animados y visualizaciones de datos en la web. La escalabilidad perfecta los hace óptimos para pantallas de alta densidad de píxeles (Retina, HiDPI).

- **WebP**
WebP es un formato moderno desarrollado por Google que soporta tanto compresión con pérdida (basada en VP8, códec de video) como sin pérdida (basada en transformaciones predictivas), así como animación y canal alpha. En términos generales, logra archivos entre un 25% y 34% más pequeños que JPEG y PNG con calidad comparable, lo que lo convierte en el formato recomendado para imágenes web modernas. La mayoría de los navegadores actuales y sistemas operativos ya lo soportan de forma nativa.





## **1.6. Procesamiento de Mapas de Bits**


<img width="842" height="387" alt="Image" src="https://github.com/user-attachments/assets/94bc6bfc-fc56-4318-a70f-c68c29d6baed" />


El procesamiento de mapas de bits (procesamiento de imágenes digitales raster) es el conjunto de técnicas computacionales que permiten analizar, transformar y mejorar imágenes almacenadas como cuadrículas de píxeles. Esta disciplina tiene aplicaciones fundamentales en la visión por computadora, el procesamiento de imágenes médicas, la corrección fotográfica, la compresión y la seguridad informática. A diferencia de la síntesis de imágenes (que genera imágenes desde cero), el procesamiento de mapas de bits trabaja sobre imágenes existentes como entrada.

### **Representación Interna de los Mapas de Bits**
Internamente, una imagen de mapa de bits se representa como una matriz bidimensional de valores numéricos. En una imagen en escala de grises, cada elemento de la matriz es un entero entre 0 (negro) y 255 (blanco). En una imagen RGB, cada posición contiene un vector de tres componentes. En imágenes con canal alpha (RGBA), cada píxel se representa con cuatro valores. La resolución espacial (número de píxeles por unidad de longitud) y la resolución de color (bits por canal) determinan la capacidad de la imagen para capturar detalle.

### **Operaciones Puntuales**
Las operaciones puntuales transforman cada píxel de forma independiente sin considerar sus vecinos. Son las operaciones más simples y eficientes computacionalmente.
- **Ajuste de brillo:** Se suma o resta una constante a todos los valores de píxel. I'(x,y) = I(x,y) + k. Si el valor supera el rango [0, 255] se aplica saturación.
- **Ajuste de contraste:** Se multiplica cada píxel por una constante. I'(x,y) = c · I(x,y). Valores de c > 1 aumentan el contraste; c < 1 lo reducen.
- **Corrección gamma:** Aplica una potencia al valor de píxel normalizado: I'(x,y) = I(x,y)^γ. Se usa para compensar las no linealidades en la respuesta de los dispositivos de captura y visualización.
Inversión: Produce el negativo de la imagen: I'(x,y) = 255 - I(x,y). Útil para visualización de imágenes médicas.
- Umbralización (Thresholding): Convierte una imagen en niveles de gris a binaria: I'(x,y) = 255 si I(x,y) ≥ umbral, 0 en otro caso. Es la base de muchos algoritmos de segmentación.

### **Operaciones de Vecindad: Filtrado Espacial**
Las operaciones de vecindad calculan el nuevo valor de cada píxel en función de él mismo y sus píxeles vecinos. Se implementan mediante la operación matemática de convolución, que aplica un núcleo (kernel) matricial sobre la imagen.
- **Filtro de suavizado (blur):** El filtro de media promedia los valores de la vecindad, reduciendo el ruido. El filtro gaussiano aplica pesos proporcionales a una función gaussiana, produciendo un suavizado más natural que preserva mejor los bordes. Se usan en preprocesamiento antes de aplicar algoritmos de detección de características.
- **Filtro de nitidez (sharpening):** El filtro laplaciano y el unsharp masking aumentan el contraste local en los bordes, produciendo la percepción de mayor nitidez. Se implementan restando una versión suavizada de la imagen a la original.
- **Detección de bordes:** Los operadores de Sobel, Prewitt y Canny calculan el gradiente de la imagen para identificar transiciones abruptas de intensidad, que corresponden a bordes de objetos. El operador de Canny es considerado el óptimo teórico para detección de bordes, con tres etapas: suavizado gaussiano, cálculo del gradiente y supresión de no máximos.
Matemáticamente, la convolución 2D de una imagen I con un núcleo K se define como: (I*K)(x,y) = Σᵢ Σⱼ I(x-i, y-j)·K(i,j), donde la suma se extiende sobre las dimensiones del núcleo.

### **Transformaciones Geométricas de Imágenes**
Las transformaciones geométricas aplicadas a imágenes de mapa de bits requieren un paso adicional respecto a las transformaciones en gráficos vectoriales: la interpolación. Al escalar, rotar o deformar una imagen, los píxeles de la imagen transformada no corresponden exactamente a posiciones enteras en la imagen original, por lo que deben calcularse sus valores por interpolación.
- **Interpolación por vecino más cercano:** Asigna a cada píxel destino el valor del píxel fuente más cercano. Es rápida pero produce bordes dentados en transformaciones no enteras.
- **Interpolación bilineal:** Promedia los cuatro píxeles vecinos más cercanos con pesos proporcionales a la distancia. Produce resultados más suaves.
- **Interpolación bicúbica:** Considera los 16 píxeles en una vecindad 4×4 con pesos derivados de funciones cúbicas. Produce los resultados más suaves y es el estándar en la mayoría de editores de imagen profesionales.

### **Histograma de Imagen y Ecualización**
El histograma de una imagen representa la distribución de frecuencias de los valores de intensidad. Es una herramienta fundamental para analizar la exposición, el contraste y el balance de tono. Un histograma concentrado en los valores bajos indica una imagen subexpuesta (oscura); concentrado en los valores altos, indica sobreexposición.
La ecualización del histograma es una técnica de mejora de contraste que redistribuye los valores de intensidad para que el histograma resultante sea aproximadamente uniforme. Se implementa calculando la función de distribución acumulada (CDF) del histograma y usándola como función de transformación de píxeles: I'(x,y) = (L-1) · CDF(I(x,y)), donde L es el número de niveles de gris.

### **Morfología Matemática**
La morfología matemática es un conjunto de técnicas no lineales que procesan imágenes binarias o en escala de grises mediante operaciones con elementos estructurantes. Las operaciones fundamentales son la erosión (reduce objetos, elimina protuberancias pequeñas) y la dilatación (expande objetos, rellena huecos pequeños). La combinación de ambas produce operaciones de mayor nivel: la apertura morfológica (erosión seguida de dilatación) suaviza contornos y elimina objetos pequeños, mientras que el cierre morfológico (dilatación seguida de erosión) rellena huecos internos y conecta objetos próximos. Estas técnicas son fundamentales en el procesamiento de imágenes médicas y en sistemas de visión por computadora para el análisis de formas.

---
## **Referencias**


Foley, J. D., van Dam, A., Feiner, S. K., y Hughes, J. F. (1996). _Introducción a la graficación por computadora_. Addison-Wesley Iberoamericana.

Friedrich G. (2009 ). Sencilla imagen de mapa de bits hecha con dos colores. Recuperado de: https://es.wikipedia.org/wiki/Imagen_de_mapa_de_bits#/media/Archivo:Aufloesung_erklaert.svg

González, R. C., y Woods, R. E. (2020). _Procesamiento digital de imágenes_ (4.ª ed.). Pearson Educación.

Hill, F. S., y Kelley, S. M. (2007). _Gráficos por computadora usando OpenGL_ (3.ª ed.). Pearson Prentice Hall.

Jouglard, Claudio & Romaris, Juan. (2025). Un Generador de Mallas Planas de Triángulos Usando Quadtrees y el Algoritmo de BresenhamA Planar Triangle Mesh Generator Using Quadtrees and Bresenham’S Algorithm. _Mecánica Computacional._ 42. 869-878. 10.70567/mc.v42.ocsid8559. 

Shark D. (2015). HSV color solid cylinder. Recuperado de: https://commons.wikimedia.org/wiki/File:HSV_color_solid_cylinder.png

Shirley, P., y Marschner, S. (2009). _Fundamentos de la síntesis de imágenes por computadora_ (3.ª ed.). Cengage Learning Editores.

Wikipedia (2004). Cubo de color RBG. Recuperado de: https://es.wikipedia.org/wiki/Teor%C3%ADa_del_color#/media/Archivo:RGB_farbwuerfel.jpg
 






